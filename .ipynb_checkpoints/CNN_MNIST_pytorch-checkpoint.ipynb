{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "237600bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cb09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc9c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e0b28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28e865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01198124885559082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075929c1e70f4fe6a3ff0e97ce6041e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010979890823364258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f2289b7e2443638528ca23bdbc56c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011992454528808594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e2537f3b3f4279b412e05cd864a2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011000633239746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4f79136bcf46ce8c3e9aa8a0b70dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train= True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f46177",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train= False, \n",
    "                                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4379801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size,\n",
    "                                         shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77d5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d34bdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = examples.next() #dataloader 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "802b4367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "         1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "         9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
       "         1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
       "         7, 8, 3, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c4ab29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape #very important to understand the NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef5e0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91e55d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "      \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1) #  Output channels: this is the number of channels in the output feature map (i.e., how many filters are being\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, padding = 2)\n",
    "        self.hidden = nn.Linear(128,64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        # self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))       \n",
    "        x = F.relu(self.conv3(x)) \n",
    "        x = F.avg_pool2d(x, [x.size(2), x.size(3)], stride=1)\n",
    "        x = x.reshape(x.shape[0],x.shape[1])\n",
    "        x = self.hidden(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92a8ae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (hidden): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62b3ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) #remember to put the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46125f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tBatch: 50\tAvg-Loss: 0.0364\n",
      "Epoch: 1\tBatch: 100\tAvg-Loss: 0.0371\n",
      "Epoch: 1\tBatch: 150\tAvg-Loss: 0.0267\n",
      "Epoch: 1\tBatch: 200\tAvg-Loss: 0.0264\n",
      "Epoch: 1\tBatch: 250\tAvg-Loss: 0.0165\n",
      "Epoch: 1\tBatch: 300\tAvg-Loss: 0.0227\n",
      "Epoch: 1\tBatch: 350\tAvg-Loss: 0.0151\n",
      "Epoch: 1\tBatch: 400\tAvg-Loss: 0.0110\n",
      "Epoch: 1\tBatch: 450\tAvg-Loss: 0.0098\n",
      "Epoch: 1\tBatch: 500\tAvg-Loss: 0.0090\n",
      "Epoch: 1\tBatch: 550\tAvg-Loss: 0.0115\n",
      "Epoch: 1\tBatch: 600\tAvg-Loss: 0.0122\n",
      "Epoch: 2\tBatch: 50\tAvg-Loss: 0.0069\n",
      "Epoch: 2\tBatch: 100\tAvg-Loss: 0.0031\n",
      "Epoch: 2\tBatch: 150\tAvg-Loss: 0.0046\n",
      "Epoch: 2\tBatch: 200\tAvg-Loss: 0.0060\n",
      "Epoch: 2\tBatch: 250\tAvg-Loss: 0.0039\n",
      "Epoch: 2\tBatch: 300\tAvg-Loss: 0.0069\n",
      "Epoch: 2\tBatch: 350\tAvg-Loss: 0.0053\n",
      "Epoch: 2\tBatch: 400\tAvg-Loss: 0.0030\n",
      "Epoch: 2\tBatch: 450\tAvg-Loss: 0.0032\n",
      "Epoch: 2\tBatch: 500\tAvg-Loss: 0.0049\n",
      "Epoch: 2\tBatch: 550\tAvg-Loss: 0.0059\n",
      "Epoch: 2\tBatch: 600\tAvg-Loss: 0.0066\n",
      "Epoch: 3\tBatch: 50\tAvg-Loss: 0.0041\n",
      "Epoch: 3\tBatch: 100\tAvg-Loss: 0.0014\n",
      "Epoch: 3\tBatch: 150\tAvg-Loss: 0.0035\n",
      "Epoch: 3\tBatch: 200\tAvg-Loss: 0.0043\n",
      "Epoch: 3\tBatch: 250\tAvg-Loss: 0.0023\n",
      "Epoch: 3\tBatch: 300\tAvg-Loss: 0.0040\n",
      "Epoch: 3\tBatch: 350\tAvg-Loss: 0.0025\n",
      "Epoch: 3\tBatch: 400\tAvg-Loss: 0.0025\n",
      "Epoch: 3\tBatch: 450\tAvg-Loss: 0.0023\n",
      "Epoch: 3\tBatch: 500\tAvg-Loss: 0.0032\n",
      "Epoch: 3\tBatch: 550\tAvg-Loss: 0.0047\n",
      "Epoch: 3\tBatch: 600\tAvg-Loss: 0.0061\n",
      "Epoch: 4\tBatch: 50\tAvg-Loss: 0.0037\n",
      "Epoch: 4\tBatch: 100\tAvg-Loss: 0.0016\n",
      "Epoch: 4\tBatch: 150\tAvg-Loss: 0.0017\n",
      "Epoch: 4\tBatch: 200\tAvg-Loss: 0.0034\n",
      "Epoch: 4\tBatch: 250\tAvg-Loss: 0.0018\n",
      "Epoch: 4\tBatch: 300\tAvg-Loss: 0.0027\n",
      "Epoch: 4\tBatch: 350\tAvg-Loss: 0.0016\n",
      "Epoch: 4\tBatch: 400\tAvg-Loss: 0.0029\n",
      "Epoch: 4\tBatch: 450\tAvg-Loss: 0.0022\n",
      "Epoch: 4\tBatch: 500\tAvg-Loss: 0.0026\n",
      "Epoch: 4\tBatch: 550\tAvg-Loss: 0.0037\n",
      "Epoch: 4\tBatch: 600\tAvg-Loss: 0.0054\n",
      "Epoch: 5\tBatch: 50\tAvg-Loss: 0.0023\n",
      "Epoch: 5\tBatch: 100\tAvg-Loss: 0.0013\n",
      "Epoch: 5\tBatch: 150\tAvg-Loss: 0.0009\n",
      "Epoch: 5\tBatch: 200\tAvg-Loss: 0.0026\n",
      "Epoch: 5\tBatch: 250\tAvg-Loss: 0.0014\n",
      "Epoch: 5\tBatch: 300\tAvg-Loss: 0.0020\n",
      "Epoch: 5\tBatch: 350\tAvg-Loss: 0.0009\n",
      "Epoch: 5\tBatch: 400\tAvg-Loss: 0.0025\n",
      "Epoch: 5\tBatch: 450\tAvg-Loss: 0.0020\n",
      "Epoch: 5\tBatch: 500\tAvg-Loss: 0.0021\n",
      "Epoch: 5\tBatch: 550\tAvg-Loss: 0.0032\n",
      "Epoch: 5\tBatch: 600\tAvg-Loss: 0.0049\n",
      "Epoch: 6\tBatch: 50\tAvg-Loss: 0.0014\n",
      "Epoch: 6\tBatch: 100\tAvg-Loss: 0.0011\n",
      "Epoch: 6\tBatch: 150\tAvg-Loss: 0.0006\n",
      "Epoch: 6\tBatch: 200\tAvg-Loss: 0.0021\n",
      "Epoch: 6\tBatch: 250\tAvg-Loss: 0.0009\n",
      "Epoch: 6\tBatch: 300\tAvg-Loss: 0.0013\n",
      "Epoch: 6\tBatch: 350\tAvg-Loss: 0.0007\n",
      "Epoch: 6\tBatch: 400\tAvg-Loss: 0.0015\n",
      "Epoch: 6\tBatch: 450\tAvg-Loss: 0.0020\n",
      "Epoch: 6\tBatch: 500\tAvg-Loss: 0.0017\n",
      "Epoch: 6\tBatch: 550\tAvg-Loss: 0.0026\n",
      "Epoch: 6\tBatch: 600\tAvg-Loss: 0.0043\n",
      "Epoch: 7\tBatch: 50\tAvg-Loss: 0.0010\n",
      "Epoch: 7\tBatch: 100\tAvg-Loss: 0.0010\n",
      "Epoch: 7\tBatch: 150\tAvg-Loss: 0.0003\n",
      "Epoch: 7\tBatch: 200\tAvg-Loss: 0.0016\n",
      "Epoch: 7\tBatch: 250\tAvg-Loss: 0.0008\n",
      "Epoch: 7\tBatch: 300\tAvg-Loss: 0.0008\n",
      "Epoch: 7\tBatch: 350\tAvg-Loss: 0.0006\n",
      "Epoch: 7\tBatch: 400\tAvg-Loss: 0.0011\n",
      "Epoch: 7\tBatch: 450\tAvg-Loss: 0.0019\n",
      "Epoch: 7\tBatch: 500\tAvg-Loss: 0.0015\n",
      "Epoch: 7\tBatch: 550\tAvg-Loss: 0.0027\n",
      "Epoch: 7\tBatch: 600\tAvg-Loss: 0.0039\n",
      "Epoch: 8\tBatch: 50\tAvg-Loss: 0.0008\n",
      "Epoch: 8\tBatch: 100\tAvg-Loss: 0.0010\n",
      "Epoch: 8\tBatch: 150\tAvg-Loss: 0.0003\n",
      "Epoch: 8\tBatch: 200\tAvg-Loss: 0.0012\n",
      "Epoch: 8\tBatch: 250\tAvg-Loss: 0.0008\n",
      "Epoch: 8\tBatch: 300\tAvg-Loss: 0.0005\n",
      "Epoch: 8\tBatch: 350\tAvg-Loss: 0.0006\n",
      "Epoch: 8\tBatch: 400\tAvg-Loss: 0.0011\n",
      "Epoch: 8\tBatch: 450\tAvg-Loss: 0.0019\n",
      "Epoch: 8\tBatch: 500\tAvg-Loss: 0.0017\n",
      "Epoch: 8\tBatch: 550\tAvg-Loss: 0.0023\n",
      "Epoch: 8\tBatch: 600\tAvg-Loss: 0.0036\n",
      "Epoch: 9\tBatch: 50\tAvg-Loss: 0.0009\n",
      "Epoch: 9\tBatch: 100\tAvg-Loss: 0.0012\n",
      "Epoch: 9\tBatch: 150\tAvg-Loss: 0.0002\n",
      "Epoch: 9\tBatch: 200\tAvg-Loss: 0.0011\n",
      "Epoch: 9\tBatch: 250\tAvg-Loss: 0.0007\n",
      "Epoch: 9\tBatch: 300\tAvg-Loss: 0.0003\n",
      "Epoch: 9\tBatch: 350\tAvg-Loss: 0.0006\n",
      "Epoch: 9\tBatch: 400\tAvg-Loss: 0.0010\n",
      "Epoch: 9\tBatch: 450\tAvg-Loss: 0.0017\n",
      "Epoch: 9\tBatch: 500\tAvg-Loss: 0.0017\n",
      "Epoch: 9\tBatch: 550\tAvg-Loss: 0.0020\n",
      "Epoch: 9\tBatch: 600\tAvg-Loss: 0.0033\n",
      "Epoch: 10\tBatch: 50\tAvg-Loss: 0.0006\n",
      "Epoch: 10\tBatch: 100\tAvg-Loss: 0.0013\n",
      "Epoch: 10\tBatch: 150\tAvg-Loss: 0.0001\n",
      "Epoch: 10\tBatch: 200\tAvg-Loss: 0.0012\n",
      "Epoch: 10\tBatch: 250\tAvg-Loss: 0.0007\n",
      "Epoch: 10\tBatch: 300\tAvg-Loss: 0.0002\n",
      "Epoch: 10\tBatch: 350\tAvg-Loss: 0.0005\n",
      "Epoch: 10\tBatch: 400\tAvg-Loss: 0.0010\n",
      "Epoch: 10\tBatch: 450\tAvg-Loss: 0.0014\n",
      "Epoch: 10\tBatch: 500\tAvg-Loss: 0.0017\n",
      "Epoch: 10\tBatch: 550\tAvg-Loss: 0.0017\n",
      "Epoch: 10\tBatch: 600\tAvg-Loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        for batch_num, (feats, labels) in enumerate(train_loader):\n",
    "            avg_loss = 0.0\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            \n",
    "            #pred\n",
    "            outputs = model(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            #compute gradients\n",
    "            loss.backward()\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            #empty grads\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch_num % 50 == 49:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db114745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2be5db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04601605488734398, 0.98575)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EVALUATION\n",
    "\n",
    "def test_classify(model, test_loader):\n",
    "model.eval()\n",
    "test_loss = []\n",
    "accuracy = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "    feats, labels = feats.to(device), labels.to(device)\n",
    "    outputs = model(feats)\n",
    "\n",
    "    _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "    pred_labels = pred_labels.view(-1)\n",
    "\n",
    "    loss = criterion(outputs, labels.long())\n",
    "\n",
    "    accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "    total += len(labels)\n",
    "    test_loss.extend([loss.item()]*feats.size()[0])\n",
    "\n",
    "\n",
    "np.mean(test_loss), accuracy/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7078d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
